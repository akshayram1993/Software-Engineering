\documentclass[â€¢]{book}
\usepackage{amsmath,amssymb}
\usepackage{algorithm,algorithmic}
\begin{document}

\title{CS3410: Software Engineering Lab\\ LR(1) parser for JavaCC}
\author{Aravind S CS11B033\\
		Akshayaram S CS11B057 \\
		Srinivasan R CS11B059 \\
		Ramnandan SK CS11B061 \\
		Adit Krishnan CS11B063
}

\maketitle

\tableofcontents

\chapter{Introduction}
\section{Context Free Grammars}
A Context Free Grammars (CFG) consists of Terminals, Non-terminals, Start Symbol and Productions.
\begin{enumerate}
\item Terminals are the basic symbols from which strings of the language are formed. Terminals are also called as tokens and correspond to the tokens that are returned by the lexical analyzer.
\item Non-Terminals are syntactic variables that denote a set of strings. Non-terminals impose a hierarchical structure on the language that is key to syntax analysis and translation.
\item A non-terminal is distinguished as the start symbol and the set of strings that are derived from the start symbol comprises of the language.
\item The productions of a grammar specify the manner in which terminals and non-terminals are combined to form strings. In a CFG:
\begin{itemize}
\item A single non-terminal to the left side of the production which is called as the head or the lhs.
\item The body or the rhs which comprises of zero or more non-terminals and terminals.
\end{itemize} 
\end{enumerate}

\subsection{Derivations}
A derivation is composed of the set of productions that must be applied to get a given string belonging to the language starting at the start symbol.

A \textit{leftmost derivation} is one in which the leftmost non-terminal is replaced with the right hand side of the production involving the non-terminal.

A \textit{rightmost derivation} is one in which the rightmost non-terminal is replaced with the right hand side of the production involving the non-terminal.

\section{Lexical Analyzers and Parsers}
 Parsers and lexical analyzers are the first two components that are present in the front end of any compiler. \textit{Lexical analyzer} reads a stream of characters from the source program and groups the characters into meaningful sequences called as \textit{tokens} which is passed to the next phase of the compiler which is the parser.  

\textit{Parser} or the syntax analyzer uses the tokens produced by the lexical analyzer to produce a tree-like intermediate representation which depicts the grammatical structure of the token stream. A typical representation is that of a syntax tree in which each interior node represents an operation and the leaves represent the operands or the arguments.

\subsection{Top Down Parsing}
 Top down parsing can be viewed as the problem of generating the parse tree for the input string in the depth first order starting at the root. The class of grammars for which one could construct predictive top down parsers with $k$ look ahead symbols is called as $LL(k)$ grammars where first $L$ refers to the left to right scanning, the second $L$ stands for leftmost derivation and $k$ refers to the number of lookahead tokens used in decision making.
 
 \subsubsection*{$LL(k)$ Grammars}
 A Context Free Grammar is called $LL(k)$ if and only if for all non-terminals $A$ and each distinct pair of production $A \rightarrow \beta$ and $A \rightarrow \gamma$ satisfy the condition $First_k(\beta) \cap First_k(\gamma) = \phi$ where $First_k(\alpha)$ the set of $k$ terminals that occur in the beginning in all strings derived from non-terminal $\alpha$.
 
 It is a well known fact that predictive parsers i.e recursive decent parsers can be constructed for $LL(k)$ grammars without backtracking and requiring $k$ lookahead tokens. $LL(k)$ parsers are easy to generate and are very efficient parsers can be generated for $LL(k)$ grammars. But it suffers from the following drawbacks:
 
 \begin{enumerate}
 \item It cannot parse any left recursive grammar.
 \item It cannot parse any ambiguous grammar (An ambiguous grammar is one in which there exists a string in the language generated by the grammar which has at least two different parse trees)
 \item Some languages have no $LL(k)$ grammars.
 
 \end{enumerate}
 
 \subsection{Bottom Up Parsing}
 A bottom up parsing corresponds to constructing a parse tree for an input from the leaves and working towards the root. One can think of bottom up parsing as a process of reducing a string to the start symbol of the grammar. The most common grammars that can be parsed with a bottom up parser is called as the $LR(k)$ parsers where first $L$ refers to left to right scanning of input, $R$ refers to constructing reverse rightmost derivation and $k$ is the number of lookahead symbols.
 
\subsubsection*{$LR(k)$ Grammars} 

A grammar is said to be $LR(k)$ if given a rightmost derivation 
$$
S = \gamma_0 \Rightarrow \gamma_1 \Rightarrow \gamma_2 \Rightarrow \cdots \gamma_k = w
$$
we can determine for each right sentential form in the derivation
\begin{itemize}
\item The handle to used 
\item The production to be used for reduction  
\end{itemize}
by scanning $\gamma_i$ from left to right and scanning at most $k$ symbols beyond right end of the handle $\gamma_i$.

We will look into more details of $LR(k)$ grammar in the next chapter.

\section{JavaCC}
JavaCC is a parser generator and a lexical analyzer written in Java programming language. It is a open source project and is similar to yacc in that it generates a parser from the formal grammar written in Extended Backus-Naur form (EBNF). JavaCC generates top down parsers and hence limited to parsing only $LL(k)$ grammars and hence cannot parse left recursive grammars. Some of the highlights of JavaCC are:

\begin{enumerate}
\item JavaCC enjoys a large user community and is by far the most widely used parser generator for Java applications.
\item An important feature of JavaCC is that both the lexical specification such as token, regular expressions, strings and the BNF for the grammar can be specified in the same file unlike the flex-Bison combination where the lexical specifications and the grammar specification are written in separate files.
\item JavaCC comes with JJtree which is an extremely powerful tree processor. It converts the given grammar file to a parse tree with internal nodes indicating the non-terminals and the leaves indicating the terminals.
\item By default JavaCC generates an $LL(1)$ parser but it is highly customizable and one can specify the number of lookahead tokens ($k$) to be used just before running it on a specific grammar file.  
\end{enumerate}
 
 JavaCC uses $LL(k)$ parser and hence cannot parse a lot of languages that can be parsed only by a $LR(1)$ parser (for example left recursive grammars). Hence, we wanted to write a $LR(1)$ parser for a restrictive choice of grammars for JavaCC.
 
 \chapter{LR(1) parsers}

This chapter gives a brief introduction about $LR(1)$ parsing algorithms and constructing the $LR(1)$ parser table that we used in writing a $LR(1)$ parser for JavaCC. Before we go into the construction, we wish to specify a few definitions and notations that we will be using throughout the chapter. We have referred extensively to \cite{aho1985} for the algorithms and the techniques explained in this chapter.

\section{Preliminaries}
Bottom up parsing or $LR(1)$ parsing is the process of \textit{reducing} a string $w$ to start symbol by applying a series of production rules. At each \textit{reduction} step, a specific substring matching the rhs of a production is replaced with the a non-terminal corresponding to the lhs or the head of the production.

Bottom up parsing during a left to right scan of the input constructs a rightmost derivation in reverse. A \textit{handle} is a substring that matches the body of a production and whose reduction represents one step in the reverse rightmost derivation.

$First(\alpha)$ is defined as the set of terminals that begin strings derived from $\alpha$. If $\alpha \Rightarrow \epsilon$, then $\epsilon \in First(\alpha)$.

\section{Shift-Reduce Parsing}
Shift-reduce parsing is a form of bottom up parsing in which a stack holds a set of grammar symbols and buffer contains the rest of the input that is to be parsed. 

Informally, during a left to right scan of the input the parser shifts 0 or more symbols to the top of the stack until it is ready to reduce a string $\beta$ of grammar symbols on top of the stack. It then reduces $\beta$ to the head of appropriate production. The parser repeats this until it has detected an error or the stack consists of the start symbol and the buffer is empty.

A shift-reduce parser has four canonical actions:

\begin{itemize}
\item \textit{Shift}: Shift the next input on top of the stack.
\item \textit{Reduce}: Right end of the handle is on top of the stack. Locate the left end of the handle within the stack. Pop the handle off the stack and push the appropriate non-terminal into the stack.
\item \textit{Accept:} Accepts the successful parsing of the given string.
\item \textit{Reject:} Discover a syntax error and call the error recovery routine.
\end{itemize}

\begin{algorithm}
\caption{Shift-Reduce Parser}
\begin{algorithmic}
\REQUIRE Goto table, action table and string w. 
\STATE push $s_0$
\STATE $token \leftarrow next\_token()$ 
\WHILE{true}
\STATE $s \leftarrow $ top of stack
\IF{$action[s,token] = $ "shift $s_i$"}
\STATE push $s_i$
\STATE $token \leftarrow next\_token()$ 
\ELSIF{$action[s,token] = $ "reduce $A \rightarrow \beta$"}
\STATE pop $|\beta|$ states from the stack
\STATE $s' = $ top of the stack
\STATE push $goto[s',A]$
\ELSIF{$action[s,token] = $ "accept"}
\STATE return
\ELSE
\STATE error()
\ENDIF
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\section{Computing First of a non-terminal}
We now give an algorithm for computing the first set of a non-terminal.

\begin{algorithm}
\caption{Computing $First(X)$}
\begin{algorithmic}
\IF{$X$ is terminal}
\STATE $FIRST(X) = X$
\ENDIF
\IF{$X \Rightarrow \epsilon$}
\STATE Add $\epsilon$ to $First(X)$.
\ENDIF
\IF{$X \Rightarrow Y_1Y_2...Y_k$}
\STATE Add $First(Y_1) - \epsilon$ to $FIRST(X)$
\FOR{i = 1 to k}
\IF{$Y_1Y_2...Y_{i} \Rightarrow \epsilon$}
\STATE Add $First(Y_{i+1}) - \epsilon$ to $FIRST(X)$
\ENDIF
\ENDFOR
\IF{$Y_1Y_2...Y_{k} \Rightarrow \epsilon$}
\STATE Add $\epsilon$ to $FIRST(X)$
\ENDIF
\ENDIF
\end{algorithmic}
\end{algorithm}

\section{$LR(1)$ items}

A $LR(1)$ item is pair $[\alpha,\beta]$ where 
\begin{itemize}
\item $\alpha$ is a production in $G$ with a $\bullet$ at some position in the rhs indicating how much of the input has been read.
\item $\beta$ is the lookahead symbol.
\end{itemize}

\subsection{$Closure1(I)$}
Given an item $[A \rightarrow \alpha \bullet B \beta, a]$ its closure contains the item and any other items that can generate legal substrings to follow $\alpha$. We now provide the algorithm for computing the closure.

\begin{algorithm}
\caption{Computing $Closure1(I)$}
\begin{algorithmic}
\REPEAT
\IF{$[A \rightarrow \alpha \bullet B \beta, a] \in I$}
\STATE Add $[B \rightarrow \bullet \gamma, b]$ to $I$ where $b \in First(\beta a)$
\ENDIF
\UNTIL{no more items can be added to $I$}
\end{algorithmic}
\end{algorithm}

\subsection{$Goto1(I)$}
Let $I$ be a set of $LR(1)$ items and $X$ be a grammar symbol. $Goto1(I,X)$ is the closure of $[A \rightarrow \alpha X \bullet \beta]$ such that $[A \rightarrow \alpha\bullet X  \beta] \in I$

We now give the algorithm for computing the $Goto1(I,X)$

\begin{algorithm}
\caption{$Goto1(I,X)$}
\begin{algorithmic}
\STATE Let $J$ be the set of items $[A \rightarrow \alpha X \bullet \beta]$ such that $[A \rightarrow \alpha\bullet X  \beta] \in I$.
\STATE return $Closure1(J)$
\end{algorithmic}
\end{algorithm}

Now, we give the algorithm for computing the $LR(1)$ item sets.

\begin{algorithm}
\caption{Computing $LR(1)$ item sets.}
\begin{algorithmic}
\end{algorithmic}
\end{algorithm}  	
\bibliographystyle{plain}
\bibliography{reference.bib} 
\end{document}